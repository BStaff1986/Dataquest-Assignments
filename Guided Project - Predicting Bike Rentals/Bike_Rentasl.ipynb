{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Washington Public Bike Rentals\n",
    "\n",
    "The dataset for this guided project is from Capital Bike Share, a bike sharing service in Washington. The dataset recorded the number of bikes rented each hour, if the renter was a casual user or registered, as well as weather data such as temperature and humidity.\n",
    "\n",
    "The goal of this assignment was to practice using Linear Regression, Decision Trees, and Random Forests using the SKLearn machine learning library. \n",
    "\n",
    "We begin by loading in the data and doing some quick exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFMVJREFUeJzt3V+MXOd93vHvI8mU/EfesG24bElZZqBQlowiNguv06pB\np3VCWQ5K6UqhEUSSpaIXkmEjBVKTvhF5FbtAYQlQJSCII1GuHYV26pIBCGkjsHORC0t0JJWqyJBs\nDcok7V3VdcDCTWBIzq8Xc1Y85hG5s+Lszoj7/QADnfPb98y85+Vqnj3vOWcmVYUkSW1XjLsDkqTJ\nYzhIkjoMB0lSh+EgSeowHCRJHYaDJKlj0XBIsjnJi0leaP57NsnnkqxNMpvkWJJnkky1ttmZ5ESS\no0m2tupbkhxOcjzJQ8u1U5KkS5Ol3OeQ5ArgNPBx4LPA/6mq/5DkC8DaqtqR5Gbg68DHgI3As8Av\nV1UleQ74bFUdSnIAeLiqnhnxPkmSLtFSp5V+HfhfVXUKuB3Y09T3AHc0y9uAp6rqjao6CZwAZpKs\nB66tqkNNuydb20iSJshSw+G3gG80y9NVNQ9QVXPAuqa+ATjV2uZMU9vA4KhjwemmJkmaMEOHQ5J3\nMTgq+GZTOn8+ys/hkKTLxFVLaHsb8JdV9aNmfT7JdFXNN1NGrzX1M8B1re02NrUL1TuSGDSS9DZU\nVUbxPEuZVvo08Met9f3APc3y3cC+Vn17kjVJNgE3AM83U09nk8wkCXBXa5u3UGN7TE19jOeee46q\nGvvjwQcfHHsfJuXhWDgWjsXFH6M01JFDkvcwOBn9b1vlLwN7k9wLvArcCVBVR5LsBY4ArwP317le\nPwA8AVwDHKiqp0exE5Kk0RoqHKrqb4BfPK/2YwaB8Vbtfx/4/beo/yXwj5feTUnSSvIO6QnX6/XG\n3YWJ4Vic41ic41gsjyXdBLdSBiekx9evqakZZmcfYWZmZmx9kKSlSkKN4YS0JGmVMBwkSR2GgySp\nw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoM\nB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqSOocIhyVSSbyY5muSVJB9PsjbJbJJjSZ5JMtVqvzPJ\niab91lZ9S5LDSY4neWg5dkiSdOmGPXJ4GDhQVTcBvwL8FbADeLaqbgQOAjsBktwM3AncBNwGPJok\nzfM8BtxXVZuBzUluHdmeSJJGZtFwSPJ+4Neq6nGAqnqjqs4CtwN7mmZ7gDua5W3AU027k8AJYCbJ\neuDaqjrUtHuytY0kaYIMc+SwCfhRkseTvJDkD5K8B5iuqnmAqpoD1jXtNwCnWtufaWobgNOt+umm\nJkmaMFcN2WYL8EBVfTfJVxhMKdV57c5fv0S7Wsu95iFJWtDv9+n3+8vy3MOEw2ngVFV9t1n/Uwbh\nMJ9kuqrmmymj15qfnwGua22/saldqH4Bu4bomiStXr1ej16v9+b67t27R/bci04rNVNHp5Jsbkqf\nAF4B9gP3NLW7gX3N8n5ge5I1STYBNwDPN1NPZ5PMNCeo72ptI0maIMMcOQB8Dvh6kncB3wM+A1wJ\n7E1yL/AqgyuUqKojSfYCR4DXgfuramHK6QHgCeAaBlc/PT2qHZEkjU7OvW9PjiQ18lMYSzA1NcPs\n7CPMzMyMrQ+StFRJqKos3nJx3iEtSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofh\nIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6S\npA7DQZLUYThIkjqGCockJ5P89yQvJnm+qa1NMpvkWJJnkky12u9MciLJ0SRbW/UtSQ4nOZ7kodHv\njiRpFIY9cvg7oFdVH62qmaa2A3i2qm4EDgI7AZLcDNwJ3ATcBjyaJM02jwH3VdVmYHOSW0e0H5Kk\nERo2HPIWbW8H9jTLe4A7muVtwFNV9UZVnQROADNJ1gPXVtWhpt2TrW0kSRNk2HAo4M+THEryb5ra\ndFXNA1TVHLCuqW8ATrW2PdPUNgCnW/XTTU2SNGGuGrLdLVX1wyS/CMwmOcYgMNrOX79Eu1rLveYh\nSVrQ7/fp9/vL8txDhUNV/bD57/9O8l+BGWA+yXRVzTdTRq81zc8A17U239jULlS/gF3D7YEkrVK9\nXo9er/fm+u7du0f23ItOKyV5T5L3NcvvBbYCLwP7gXuaZncD+5rl/cD2JGuSbAJuAJ5vpp7OJplp\nTlDf1dpGkjRBhjlymAa+naSa9l+vqtkk3wX2JrkXeJXBFUpU1ZEke4EjwOvA/VW1MOX0APAEcA1w\noKqeHuneSJJGIufetyfHIIjG16+pqRlmZx9hZmZm8caSNCGSUFVZvOXivENaktRhOEiSOgwHSVKH\n4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgO\nkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUMHQ5JrkjyQpL9zfraJLNJjiV5JslU\nq+3OJCeSHE2ytVXfkuRwkuNJHhrtrkiSRmUpRw6fB4601ncAz1bVjcBBYCdAkpuBO4GbgNuAR5Ok\n2eYx4L6q2gxsTnLrJfZfkrQMhgqHJBuBTwF/2CrfDuxplvcAdzTL24CnquqNqjoJnABmkqwHrq2q\nQ027J1vbSJImyLBHDl8Bfg+oVm26quYBqmoOWNfUNwCnWu3ONLUNwOlW/XRTkyRNmKsWa5DkN4H5\nqnopSe8iTesiP3sbdrWWe81DkrSg3+/T7/eX5bkXDQfgFmBbkk8B7wauTfI1YC7JdFXNN1NGrzXt\nzwDXtbbf2NQuVL+AXUPugiStTr1ej16v9+b67t27R/bci04rVdUXq+oDVfVLwHbgYFX9DvBnwD1N\ns7uBfc3yfmB7kjVJNgE3AM83U09nk8w0J6jvam0jSZogwxw5XMiXgL1J7gVeZXCFElV1JMleBlc2\nvQ7cX1ULU04PAE8A1wAHqurpS3h9SdIyybn37cmRpEZ+CmMJpqZmmJ19hJmZmbH1QZKWKglVlcVb\nLs47pCVJHYaDJKnDcJAkdRgOkqQOw0GS1OHVSm9hamqGK688w49//IOx9WF6+nrm5k6O7fUlvfOM\n8mqlS7nP4bI2CIbxBdT8/Ej+fSXpbXFaSZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgO\nkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkjkXDIcnVSZ5L8mKSl5M82NTX\nJplNcizJM0mmWtvsTHIiydEkW1v1LUkOJzme5KHl2SVJ0qVaNByq6qfAv6yqjwIfAW5LMgPsAJ6t\nqhuBg8BOgCQ3A3cCNwG3AY8mWfhas8eA+6pqM7A5ya2j3iFJ0qUbalqpqv6mWbyawVeLFnA7sKep\n7wHuaJa3AU9V1RtVdRI4AcwkWQ9cW1WHmnZPtraRJE2QocIhyRVJXgTmgD9v3uCnq2oeoKrmgHVN\n8w3AqdbmZ5raBuB0q366qUmSJsxVwzSqqr8DPprk/cC3k3yYwdHDzzUbbdd2tZZ7zUOStKDf79Pv\n95fluYcKhwVV9X+T9IFPAvNJpqtqvpkyeq1pdga4rrXZxqZ2ofoF7FpK1yRp1en1evR6vTfXd+/e\nPbLnHuZqpX+wcCVSkncDvwEcBfYD9zTN7gb2Ncv7ge1J1iTZBNwAPN9MPZ1NMtOcoL6rtY0kaYIM\nc+TwD4E9Sa5gECZ/UlUHknwH2JvkXuBVBlcoUVVHkuwFjgCvA/dX1cKU0wPAE8A1wIGqenqkeyNJ\nGomce9+eHElq5KcwlmBqaoazZw8xzj5AmMR/G0mTKwlVlcVbLs47pCVJHYaDJKnDcJAkdRgOkqQO\nw0GS1GE4SJI6lnSHtFbS1Zz7MNvxmJ6+nrm5k2Ptg6TxMBwm1k8Z730WMD8/3nCSND5OK0mSOgwH\nSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAk\ndRgOkqSORcMhycYkB5O8kuTlJJ9r6muTzCY5luSZJFOtbXYmOZHkaJKtrfqWJIeTHE/y0PLskiTp\nUg1z5PAG8O+q6sPAPwUeSPIhYAfwbFXdCBwEdgIkuRm4E7gJuA14NOe+0uwx4L6q2gxsTnLrSPdG\nkjQSi4ZDVc1V1UvN8k+Ao8BG4HZgT9NsD3BHs7wNeKqq3qiqk8AJYCbJeuDaqjrUtHuytY0kaYIs\n6ZxDkg8CHwG+A0xX1TwMAgRY1zTbAJxqbXamqW0ATrfqp5uaJGnCDP0d0kneB3wL+HxV/STJ+V9w\nPOIvPN7VWu41D0nSgn6/T7/fX5bnHiocklzFIBi+VlX7mvJ8kumqmm+mjF5r6meA61qbb2xqF6pf\nwK5huiZJq1av16PX6725vnv37pE997DTSn8EHKmqh1u1/cA9zfLdwL5WfXuSNUk2ATcAzzdTT2eT\nzDQnqO9qbSNJmiCLHjkkuQX4beDlJC8ymD76IvBlYG+Se4FXGVyhRFUdSbIXOAK8DtxfVQtTTg8A\nTwDXAAeq6unR7o4kaRRy7n17cgzOZ4yvX1NTM5w9e4hx9gEy5tcf9GESfz8kvbUkVFUWb7k475CW\nJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6hj64zO0Gl3NuQ/UHY/p6euZmzs51j5Iq5HhoIv4KeO+\n12J+frzhJK1WTitJkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofh\nIEnqMBwkSR2GgySpw3CQJHUYDpKkjkXDIclXk8wnOdyqrU0ym+RYkmeSTLV+tjPJiSRHk2xt1bck\nOZzkeJKHRr8rkqRRGebI4XHg1vNqO4Bnq+pG4CCwEyDJzcCdwE3AbcCjOfdVYo8B91XVZmBzkvOf\nU5I0IRYNh6r6C+CvzyvfDuxplvcAdzTL24CnquqNqjoJnABmkqwHrq2qQ027J1vbSJImzNs957Cu\nquYBqmoOWNfUNwCnWu3ONLUNwOlW/XRTkyRNoFF9h/QyfNHwrtZyr3lo9bmaczOTK296+nrm5k6O\n7fWli+n3+/T7/WV57rcbDvNJpqtqvpkyeq2pnwGua7Xb2NQuVL+IXW+za7q8/JRl+dtjSPPz4wsm\naTG9Xo9er/fm+u7du0f23MNOK6V5LNgP3NMs3w3sa9W3J1mTZBNwA/B8M/V0NslMc4L6rtY2kqQJ\ns+iRQ5JvMJjT+ftJvg88CHwJ+GaSe4FXGVyhRFUdSbIXOAK8DtxfVQt/9j0APAFcAxyoqqdHuyuS\npFHJuffuyZGkxjmVMDU1w9mzhxhnHwYHauP+t7EPECbx/xHprSShqkYyF+od0pKkDsNBktRhOEiS\nOgwHSVKH4SBJ6jAcJEkdo/r4DOkyNd6P7wA/wkPjYThIFzXej+8AP8JD4+G0kiSpw3CQJHUYDpKk\nDsNBktRhOEiSOgwHSVKH4SBJ6vA+B2nieSOeVp7hIE08b8TTynNaSZLUYThIkjoMB0lSh+EgSerw\nhLSkIYz3iimvllp5K37kkOSTSf4qyfEkX1jp15f0dixcMTWex/z8HEnG+li//oPLP8wTZEXDIckV\nwCPArcCHgU8n+dBK9uGdpz/uDkyQ/rg7MEH64+7ACrtYOP23i/xslAH16vLv5gRZ6SOHGeBEVb1a\nVa8DTwG3r3Af3mH64+7ABOmPuwMTpD/uDkyQ/rg7cFla6XDYAJxqrZ9uapKkCTKxJ6Tf//5/PbbX\n/tu/PT6215Y0qVbXx5ikauVuy0/yq8Cuqvpks74DqKr68nntxvtZAZL0DlVVI0mwlQ6HK4FjwCeA\nHwLPA5+uqqMr1glJ0qJWdFqpqn6W5LPALIPzHV81GCRp8qzokYMk6Z1hoj4+Y7XdIJdkY5KDSV5J\n8nKSzzX1tUlmkxxL8kySqdY2O5OcSHI0ydbx9X70klyR5IUk+5v1VTkOAEmmknyz2b9Xknx8tY5H\nkt9N8j+SHE7y9SRrVstYJPlqkvkkh1u1Je97ki3N+B1P8tBQL15VE/FgEFT/E7geeBfwEvChcfdr\nmfd5PfCRZvl9DM7HfAj4MvDvm/oXgC81yzcDLzKYDvxgM14Z936McDx+F/jPwP5mfVWOQ7OPTwCf\naZavAqZW43gA/wj4HrCmWf8T4O7VMhbAPwc+Ahxu1Za878BzwMea5QPArYu99iQdOay6G+Sqaq6q\nXmqWfwIcBTYy2O89TbM9wB3N8jbgqap6o6pOAicYjNs7XpKNwKeAP2yVV904ACR5P/BrVfU4QLOf\nZ1ml4wFcCbw3yVXAu4EzrJKxqKq/AP76vPKS9j3JeuDaqjrUtHuytc0FTVI4rOob5JJ8kMFfCN8B\npqtqHgYBAqxrmp0/Rme4fMboK8Dv8fNfebYaxwFgE/CjJI8302x/kOQ9rMLxqKofAP8R+D6D/Tpb\nVc+yCseiZd0S930Dg/fTBUO9t05SOKxaSd4HfAv4fHMEcf5VApf1VQNJfhOYb46iLnaN9mU9Di1X\nAVuA/1RVW4D/B+xglf1eACT5BQZ/KV/PYIrpvUl+m1U4FhexLPs+SeFwBvhAa31jU7usNYfK3wK+\nVlX7mvJ8kunm5+uB15r6GeC61uaXyxjdAmxL8j3gj4F/leRrwNwqG4cFp4FTVfXdZv1PGYTFavu9\nAPh14HtV9eOq+hnwbeCfsTrHYsFS9/1tjckkhcMh4IYk1ydZA2wH9o+5Tyvhj4AjVfVwq7YfuKdZ\nvhvY16pvb67W2ATcwOBGwne0qvpiVX2gqn6Jwb/7war6HeDPWEXjsKCZMjiVZHNT+gTwCqvs96Lx\nfeBXk1yTwWdXfAI4wuoai/DzR9RL2vdm6ulskplmDO9qbXNh4z4bf96Z+U8yuGLnBLBj3P1Zgf29\nBfgZgyuzXgReaMbg7wHPNmMxC/xCa5udDK5COApsHfc+LMOY/AvOXa20msfhVxj8wfQS8F8YXK20\nKscDeLDZr8MMTsC+a7WMBfAN4AcMPrP8+8BngLVL3XfgnwAvN++tDw/z2t4EJ0nqmKRpJUnShDAc\nJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSx/8H4Wler3BCYDMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19570e6a048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant       0.278379\n",
      "season        0.178056\n",
      "yr            0.250495\n",
      "mnth          0.120638\n",
      "hr            0.394071\n",
      "holiday      -0.030927\n",
      "weekday       0.026900\n",
      "workingday    0.030284\n",
      "weathersit   -0.142426\n",
      "temp          0.404772\n",
      "atemp         0.400929\n",
      "hum          -0.322911\n",
      "windspeed     0.093234\n",
      "casual        0.694564\n",
      "registered    0.972151\n",
      "cnt           1.000000\n",
      "Name: cnt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "bike_rentals = pd.read_csv('bike_rental_hour.csv')\n",
    "print(bike_rentals.head())\n",
    "\n",
    "plt.hist(bike_rentals['cnt'])\n",
    "plt.show()\n",
    "\n",
    "print(bike_rentals.corr()['cnt'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do some feature engineering before creating the machine learning models. We will collapse the 24 hour time period into 4 six-hour groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating (numeric) labels to divide the day into 4 parts\n",
    "def assign_label(hour):\n",
    "    if 0 <= hour < 6:\n",
    "        return 4\n",
    "    elif 6 <= hour < 12:\n",
    "        return 1\n",
    "    elif 12 <= hour < 18:\n",
    "        return 2\n",
    "    elif 18 <= hour <= 24:\n",
    "        return 3\n",
    "    \n",
    "bike_rentals['time_label'] = bike_rentals['hr'].apply(assign_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Before training the machine learning model, we will split the data into train and test sets. A list of features will be created from the columns of the bike rental dataset with our label (\"cnt\") and other useless features dropped. \n",
    "\n",
    "With the train and test sets ready and the features selected, the linear regression model can will then be created, trained, and tested. The error metric used for all the machine learning models in this assignment will be mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean Squared Error:  16839.3444248\n",
      "Root Mean Squared Error:  129.766499624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Creating a test and training set\n",
    "train = bike_rentals.sample(frac=.8)\n",
    "test = bike_rentals[~bike_rentals.index.isin(train.index)]\n",
    "\n",
    "# Preparing the columns wanted for the regression\n",
    "predictors = list(bike_rentals.columns)\n",
    "predictors.remove(\"cnt\")\n",
    "predictors.remove(\"casual\")\n",
    "predictors.remove(\"registered\")\n",
    "predictors.remove(\"dteday\")\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[predictors], train['cnt'])\n",
    "predictions = lr.predict(test[predictors])\n",
    "mse = mean_squared_error(test['cnt'], predictions)\n",
    "print('\\n')\n",
    "print(\"Mean Squared Error: \",mse)\n",
    "print(\"Root Mean Squared Error: \", mse**.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "The train and test sets will now be applied to a decision tree model.  After the initial model is trained and tested, another decision tree will be modeled with some tinkering of the hyper-parameters with the hopes of tuning the model for more accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results of Decision Tree\n",
      "Mean Squared Error:  3397.37974684\n",
      "Root Mean Squared Error:  58.2870461324\n",
      "\n",
      "\n",
      "Result of Tweaked Decision Tree\n",
      "Mean Squared Error:  2969.13157616\n",
      "Root Mean Squared Error:  54.4897382648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Instantiate a decision tree regressor. Train. Test. \n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(train[predictors], train['cnt'])\n",
    "dt_predictions = dt.predict(test[predictors])\n",
    "\n",
    "mse_dt = mean_squared_error(test['cnt'], dt_predictions)\n",
    "print('\\n')\n",
    "print(\"Results of Decision Tree\")\n",
    "print(\"Mean Squared Error: \",mse_dt)\n",
    "print(\"Root Mean Squared Error: \", mse_dt**.5)\n",
    "\n",
    "# Tinker with the regressor to improve accuracy\n",
    "dt = DecisionTreeRegressor(min_samples_leaf=15, max_depth=25)\n",
    "dt.fit(train[predictors], train['cnt'])\n",
    "dt_predictions = dt.predict(test[predictors])\n",
    "\n",
    "mse_dt = mean_squared_error(test['cnt'], dt_predictions)\n",
    "print('\\n')\n",
    "print(\"Result of Tweaked Decision Tree\")\n",
    "print(\"Mean Squared Error: \",mse_dt)\n",
    "print(\"Root Mean Squared Error: \", mse_dt**.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "Similiarly to the decision trees above, this random forest model will be created twice with the second iteration having it's hyper-parameters tuned. An added avenue of exploration here is using the trained model to test itself against the training data it saw while it was being fit. The difference or similarity between the error scores could be an indication that our model is overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Result of Random Forest\n",
      "Predictions Using Test Data\n",
      "Mean Squared Error:  2071.95911105\n",
      "Root Mean Squared Error:  45.5187775654\n",
      "Predictions Using Training Data\n",
      "Mean Squared Error:  342.400281954\n",
      "Root Mean Squared Error:  18.5040612286\n",
      "\n",
      "\n",
      "Result of Tweaked Random Forest\n",
      "Predictions Using Test Data\n",
      "Mean Squared Error:  3370.31828119\n",
      "Root Mean Squared Error:  58.0544423898\n",
      "Predictions Using Training Data\n",
      "Mean Squared Error:  2747.28488927\n",
      "Root Mean Squared Error:  52.4145484505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a random forest and fit it\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(train[predictors], train['cnt'])\n",
    "# Create predictions on test data\n",
    "rf_predictions = rf.predict(test[predictors])\n",
    "mse_rf = mean_squared_error(test['cnt'], rf_predictions)\n",
    "# Create predictions on training data to test for overfitting\n",
    "rf_predictions_train = rf.predict(train[predictors])\n",
    "mse_rf_training = mean_squared_error(train['cnt'], rf_predictions_train)\n",
    "print('\\n')\n",
    "print(\"Result of Random Forest\")\n",
    "print(\"Predictions Using Test Data\")\n",
    "print(\"Mean Squared Error: \",mse_rf)\n",
    "print(\"Root Mean Squared Error: \", mse_rf**.5)\n",
    "print(\"Predictions Using Training Data\")\n",
    "print(\"Mean Squared Error: \",mse_rf_training)\n",
    "print(\"Root Mean Squared Error: \", mse_rf_training**.5)\n",
    "\n",
    "# Tweak the Random Forest \n",
    "rf = RandomForestRegressor(min_samples_leaf=27, max_depth=17)\n",
    "rf.fit(train[predictors], train['cnt'])\n",
    "rf_predictions = rf.predict(test[predictors])\n",
    "mse_rf = mean_squared_error(test['cnt'], rf_predictions)\n",
    "rf_predictions_train = rf.predict(train[predictors])\n",
    "mse_rf_training = mean_squared_error(train['cnt'], rf_predictions_train)\n",
    "        \n",
    "print('\\n')\n",
    "print(\"Result of Tweaked Random Forest\")\n",
    "print(\"Predictions Using Test Data\")\n",
    "print(\"Mean Squared Error: \",mse_rf)\n",
    "print(\"Root Mean Squared Error: \", mse_rf**.5)\n",
    "print(\"Predictions Using Training Data\")\n",
    "print(\"Mean Squared Error: \",mse_rf_training)\n",
    "print(\"Root Mean Squared Error: \", mse_rf_training**.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion we can see that the Random Forest algorithm outperformed both Linear Regression and the Decision Tree. Although the tweaked Random Forest performed worse, the result is not alarming. A better tuning could be found if extra time is spent tuning the hyper-parameters. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
